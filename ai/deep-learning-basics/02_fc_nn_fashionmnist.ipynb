{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2편: 완전연결 신경망으로 FashionMNIST 분류하기\n",
    "\n",
    "이 노트북에서는 다음을 학습합니다:\n",
    "- FashionMNIST 데이터셋의 구조와 시각화\n",
    "- DataLoader를 사용한 배치 학습\n",
    "- 1계층 → 다계층 완전연결(FC) 신경망 구현\n",
    "- **파라미터 폭발 문제**를 직접 체감"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FashionMNIST 데이터셋\n",
    "\n",
    "FashionMNIST는 Zalando에서 공개한 패션 아이템 이미지 데이터셋입니다.\n",
    "- **이미지**: 28 × 28 그레이스케일\n",
    "- **학습 데이터**: 60,000장\n",
    "- **테스트 데이터**: 10,000장\n",
    "- **클래스**: 10가지 (T-shirt, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# FashionMNIST 다운로드\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# 클래스 이름 매핑\n",
    "class_names = [\n",
    "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
    "]\n",
    "\n",
    "print(f\"학습 데이터: {len(training_data)}장\")\n",
    "print(f\"테스트 데이터: {len(test_data)}장\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 이미지 시각화\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    image, label = training_data[i]\n",
    "    ax.imshow(image.squeeze(), cmap=\"gray\")\n",
    "    ax.set_title(class_names[label], fontsize=10)\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(\"FashionMNIST Samples\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DataLoader로 배치 학습 준비\n",
    "\n",
    "- **Dataset**: 개별 데이터(이미지, 레이블) 접근\n",
    "- **DataLoader**: 배치 단위로 데이터를 묶어서 반복자 제공\n",
    "- **batch_size**: 한 번에 학습할 데이터 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "print(f\"전체 학습 데이터: {len(training_data)}장\")\n",
    "print(f\"배치 크기: {batch_size}\")\n",
    "print(f\"배치 수: {len(train_dataloader)} (= {len(training_data)} / {batch_size} 올림)\")\n",
    "\n",
    "# 첫 번째 배치 확인\n",
    "for images, labels in train_dataloader:\n",
    "    print(f\"\\n배치 이미지 shape: {images.shape}\")\n",
    "    print(f\"  → {images.shape[0]}장 × {images.shape[2]}×{images.shape[3]} 이미지 × {images.shape[1]} 채널\")\n",
    "    print(f\"배치 레이블 shape: {labels.shape}\")\n",
    "    print(f\"첫 번째 레이블: {labels[0]} ({class_names[labels[0]]})\")\n",
    "    print(f\"\\nFlatten 후: {images.view(-1, 28 * 28).shape}  (28×28=784 차원 벡터)\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 1계층 완전연결 신경망\n",
    "\n",
    "가장 단순한 구조: 784차원 입력 → 10개 클래스 출력\n",
    "\n",
    "```\n",
    "이미지 (28×28) → Flatten (784) → Linear(784, 10) → 출력 (10 클래스)\n",
    "```\n",
    "\n",
    "파라미터 수: 784 × 10 + 10(bias) = **7,850개**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"사용 디바이스: {device}\")\n",
    "\n",
    "class SingleLayerNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "single_net = SingleLayerNet().to(device)\n",
    "print(single_net)\n",
    "\n",
    "# 파라미터 수 계산\n",
    "total_params = sum(p.numel() for p in single_net.parameters())\n",
    "print(f\"\\n총 파라미터 수: {total_params:,}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1계층 모델 학습\n",
    "optimizer = torch.optim.SGD(single_net.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "single_costs = []\n",
    "single_times = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    start_time = time.time()\n",
    "    avg_cost = 0\n",
    "    total_batch = len(train_dataloader)\n",
    "\n",
    "    for X, Y in train_dataloader:\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = single_net(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost.item() / total_batch\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    single_costs.append(avg_cost)\n",
    "    single_times.append(elapsed)\n",
    "    print(f\"Epoch {epoch+1:02d} | cost = {avg_cost:.6f} | time = {elapsed:.2f}s\")\n",
    "\n",
    "print(f\"\\n평균 에포크 시간: {sum(single_times)/len(single_times):.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 다계층 완전연결 신경망\n",
    "\n",
    "계층을 깊게 쌓으면 더 복잡한 패턴을 학습할 수 있지만, **파라미터 수가 폭발적으로 증가**합니다.\n",
    "\n",
    "```\n",
    "이미지(784) → Linear(784, 7840) → Linear(7840, 7840) → Linear(7840, 10) → 출력\n",
    "```\n",
    "\n",
    "파라미터 수:\n",
    "- 1층: 784 × 7,840 + 7,840 = 6,154,240\n",
    "- 2층: 7,840 × 7,840 + 7,840 = 61,473,440\n",
    "- 3층: 7,840 × 10 + 10 = 78,410\n",
    "- **합계: 약 6,770만개** (1계층 대비 약 8,600배!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(28 * 28, 28 * 28 * 10)\n",
    "        self.linear2 = nn.Linear(28 * 28 * 10, 28 * 28 * 10)\n",
    "        self.linear3 = nn.Linear(28 * 28 * 10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "multi_net = MultiLayerNet().to(device)\n",
    "print(multi_net)\n",
    "\n",
    "total_params_multi = sum(p.numel() for p in multi_net.parameters())\n",
    "print(f\"\\n총 파라미터 수: {total_params_multi:,}개\")\n",
    "print(f\"1계층 대비 {total_params_multi / total_params:.0f}배 증가!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다계층 모델 학습\n",
    "optimizer_multi = torch.optim.SGD(multi_net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "multi_costs = []\n",
    "multi_times = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    start_time = time.time()\n",
    "    avg_cost = 0\n",
    "    total_batch = len(train_dataloader)\n",
    "\n",
    "    for X, Y in train_dataloader:\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer_multi.zero_grad()\n",
    "        hypothesis = multi_net(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer_multi.step()\n",
    "\n",
    "        avg_cost += cost.item() / total_batch\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    multi_costs.append(avg_cost)\n",
    "    multi_times.append(elapsed)\n",
    "    print(f\"Epoch {epoch+1:02d} | cost = {avg_cost:.6f} | time = {elapsed:.2f}s\")\n",
    "\n",
    "print(f\"\\n평균 에포크 시간: {sum(multi_times)/len(multi_times):.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 비교: 1계층 vs 다계층 FC\n",
    "\n",
    "두 모델의 학습 과정을 비교하여 파라미터 폭발의 영향을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Cost 비교\n",
    "epochs = range(1, 11)\n",
    "axes[0].plot(epochs, single_costs, \"o-\", label=f\"1-Layer ({total_params:,} params)\")\n",
    "axes[0].plot(epochs, multi_costs, \"s-\", label=f\"3-Layer ({total_params_multi:,} params)\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Cost\")\n",
    "axes[0].set_title(\"Cost Comparison\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 시간 비교\n",
    "axes[1].plot(epochs, single_times, \"o-\", label=\"1-Layer\")\n",
    "axes[1].plot(epochs, multi_times, \"s-\", label=\"3-Layer\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Time (seconds)\")\n",
    "axes[1].set_title(\"Training Time per Epoch\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== 요약 ===\")\n",
    "print(f\"{'':15s} {'1계층':>12s} {'3계층':>12s} {'배율':>8s}\")\n",
    "print(f\"{'파라미터 수':15s} {total_params:>12,} {total_params_multi:>12,} {total_params_multi/total_params:>7.0f}x\")\n",
    "print(f\"{'평균 시간(s)':15s} {sum(single_times)/10:>12.2f} {sum(multi_times)/10:>12.2f} {sum(multi_times)/sum(single_times):>7.1f}x\")\n",
    "print(f\"{'최종 cost':15s} {single_costs[-1]:>12.6f} {multi_costs[-1]:>12.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 완전연결 신경망의 한계\n",
    "\n",
    "현재는 28×28의 아주 작은 그레이스케일 이미지를 학습하는 경우입니다.\n",
    "\n",
    "하지만 실제에서는:\n",
    "- **4K 이미지**: 3840 × 2160 × 3 = 24,883,200 차원\n",
    "- **수십~수백 계층**으로 구성\n",
    "- **수백만 장**의 학습 데이터\n",
    "\n",
    "FC 레이어로 4K 이미지를 학습하면 **1계층만으로도 수조 개의 파라미터**가 필요합니다.\n",
    "이는 메모리와 연산 측면에서 학습이 **사실상 불가능**합니다.\n",
    "\n",
    "근본적인 문제: FC 레이어는 **이미지의 공간적 구조(인접 픽셀 간의 관계)**를 전혀 활용하지 못합니다.\n",
    "\n",
    "→ **다음 노트북에서 CNN(합성곱 신경망)**으로 이 문제를 해결합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
