{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4편: GAN으로 이미지 생성하기\n",
    "\n",
    "이 노트북에서는 다음을 학습합니다:\n",
    "- 분류 모델 vs 생성 모델의 차이\n",
    "- GAN(Generative Adversarial Network)의 구조와 원리\n",
    "- Generator와 Discriminator 구현\n",
    "- FashionMNIST 이미지를 생성하는 GAN 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 생성 모델이란?\n",
    "\n",
    "지금까지 학습한 모델은 **분류(Discriminative) 모델**입니다:\n",
    "- 입력: 이미지 → 출력: 클래스 레이블\n",
    "- \"이 이미지가 무엇인지\" 판별\n",
    "\n",
    "**생성(Generative) 모델**은 반대입니다:\n",
    "- 입력: 랜덤 노이즈 → 출력: 새로운 이미지\n",
    "- \"학습 데이터와 비슷한 새로운 데이터\" 생성\n",
    "- 데이터의 **확률 분포**를 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GAN의 구조\n",
    "\n",
    "GAN은 두 개의 신경망이 서로 **경쟁(적대적 학습)**하며 발전합니다:\n",
    "\n",
    "- **Generator(생성자)**: 랜덤 노이즈로부터 가짜 이미지를 생성하는 \"위조범\"\n",
    "- **Discriminator(판별자)**: 진짜/가짜 이미지를 구별하는 \"감정사\"\n",
    "\n",
    "학습이 진행되면:\n",
    "- Generator는 점점 정교한 가짜 이미지를 만들고\n",
    "- Discriminator는 점점 정밀하게 판별하려 하고\n",
    "- 최종적으로 Generator가 진짜와 구별 불가능한 이미지를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"사용 디바이스: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비 (정규화: [0,1] → [-1,1])\n",
    "standardizer = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "train_data = dsets.FashionMNIST(root=\"data/\", train=True, transform=standardizer, download=True)\n",
    "test_data = dsets.FashionMNIST(root=\"data/\", train=False, transform=standardizer, download=True)\n",
    "\n",
    "batch_size = 200\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size, shuffle=True)\n",
    "\n",
    "print(f\"학습 데이터: {len(train_data)}장, 배치 수: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 시각화 헬퍼\n",
    "def show_image(img):\n",
    "    \"\"\"단일 이미지 출력 (정규화 복원)\"\"\"\n",
    "    img = (img + 1) / 2  # [-1,1] → [0,1]\n",
    "    img = img.squeeze()\n",
    "    plt.imshow(img.numpy(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def show_grid(img):\n",
    "    \"\"\"이미지 그리드 출력\"\"\"\n",
    "    img = utils.make_grid(img.cpu().detach())\n",
    "    img = (img + 1) / 2\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 구현\n",
    "\n",
    "### Generator (생성자)\n",
    "```\n",
    "랜덤 노이즈 (100) → Linear(256) → ReLU → Linear(256) → ReLU → Linear(784) → Tanh → 이미지 (28×28)\n",
    "```\n",
    "\n",
    "### Discriminator (판별자)\n",
    "```\n",
    "이미지 (784) → Linear(256) → LeakyReLU → Linear(256) → LeakyReLU → Linear(1) → Sigmoid → 확률 [0,1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_noise = 100   # 노이즈 차원\n",
    "d_hidden = 256  # 은닉층 차원\n",
    "\n",
    "def sample_noise(batch_size=1, d_noise=100):\n",
    "    \"\"\"랜덤 노이즈 생성\"\"\"\n",
    "    return torch.randn(batch_size, d_noise, device=device)\n",
    "\n",
    "# Generator: 노이즈 → 이미지\n",
    "G = nn.Sequential(\n",
    "    nn.Linear(d_noise, d_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(d_hidden, d_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(d_hidden, 28 * 28),\n",
    "    nn.Tanh(),  # 출력 범위를 [-1, 1]로 제한\n",
    ").to(device)\n",
    "\n",
    "# Discriminator: 이미지 → 진짜일 확률\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(28 * 28, d_hidden),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(d_hidden, d_hidden),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(d_hidden, 1),\n",
    "    nn.Sigmoid(),  # 출력: 진짜일 확률 [0, 1]\n",
    ").to(device)\n",
    "\n",
    "print(\"=== Generator ===\")\n",
    "print(f\"파라미터 수: {sum(p.numel() for p in G.parameters()):,}\")\n",
    "print(f\"\\n=== Discriminator ===\")\n",
    "print(f\"파라미터 수: {sum(p.numel() for p in D.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 전 Generator의 출력 확인 (완전한 노이즈)\n",
    "z = sample_noise()\n",
    "fake_img = G(z).view(28, 28)\n",
    "print(\"학습 전 Generator 출력 (랜덤 노이즈에서 생성):\")\n",
    "show_image(fake_img.cpu().detach())\n",
    "\n",
    "# Discriminator의 판별 결과\n",
    "z = sample_noise(5)\n",
    "fake_batch = G(z)\n",
    "probs = D(fake_batch)\n",
    "print(f\"Discriminator 판별 결과 (학습 전): {probs.data.squeeze().tolist()}\")\n",
    "print(f\"  → 약 0.5 (진짜/가짜 구별 못함)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GAN 학습\n",
    "\n",
    "매 배치마다 두 단계로 학습합니다:\n",
    "\n",
    "**Discriminator 학습:**\n",
    "- 진짜 이미지 → D → 1에 가까워지도록 (진짜를 진짜로 판별)\n",
    "- 가짜 이미지 → D → 0에 가까워지도록 (가짜를 가짜로 판별)\n",
    "\n",
    "**Generator 학습:**\n",
    "- 가짜 이미지 → D → 1에 가까워지도록 (가짜를 진짜처럼 속이기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(generator, discriminator, opt_g, opt_d):\n",
    "    \"\"\"1 에포크 학습\"\"\"\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    for img_batch, _ in train_loader:\n",
    "        img_batch = img_batch.to(device)\n",
    "\n",
    "        # --- Discriminator 학습 ---\n",
    "        opt_d.zero_grad()\n",
    "        # 진짜 이미지에 대한 판별\n",
    "        p_real = discriminator(img_batch.view(-1, 28 * 28))\n",
    "        # 가짜 이미지에 대한 판별\n",
    "        p_fake = discriminator(generator(sample_noise(batch_size, d_noise)))\n",
    "\n",
    "        # 진짜는 1, 가짜는 0으로 판별하도록 학습\n",
    "        loss_real = -torch.log(p_real).mean()\n",
    "        loss_fake = -torch.log(1.0 - p_fake).mean()\n",
    "        loss_d = loss_real + loss_fake\n",
    "\n",
    "        loss_d.backward()\n",
    "        opt_d.step()\n",
    "\n",
    "        # --- Generator 학습 ---\n",
    "        opt_g.zero_grad()\n",
    "        # 가짜 이미지를 진짜처럼 속이도록 학습\n",
    "        p_fake = discriminator(generator(sample_noise(batch_size, d_noise)))\n",
    "        loss_g = -torch.log(p_fake).mean()\n",
    "\n",
    "        loss_g.backward()\n",
    "        opt_g.step()\n",
    "\n",
    "\n",
    "def evaluate(generator, discriminator):\n",
    "    \"\"\"테스트 데이터로 평가\"\"\"\n",
    "    p_real, p_fake = 0.0, 0.0\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_batch, _ in test_loader:\n",
    "            img_batch = img_batch.to(device)\n",
    "            p_real += torch.sum(discriminator(img_batch.view(-1, 28 * 28))).item() / len(test_data)\n",
    "            p_fake += torch.sum(discriminator(generator(sample_noise(batch_size, d_noise)))).item() / len(test_data)\n",
    "\n",
    "    return p_real, p_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 초기화\n",
    "def init_weights(model):\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_normal_(p)\n",
    "        else:\n",
    "            nn.init.uniform_(p, 0.1, 0.2)\n",
    "\n",
    "init_weights(G)\n",
    "init_weights(D)\n",
    "\n",
    "opt_g = optim.Adam(G.parameters(), lr=0.0002)\n",
    "opt_d = optim.Adam(D.parameters(), lr=0.0002)\n",
    "\n",
    "# 학습 기록\n",
    "p_real_history = []\n",
    "p_fake_history = []\n",
    "\n",
    "total_epochs = 100\n",
    "print(f\"GAN 학습 시작 ({total_epochs} 에포크)...\\n\")\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    train_one_epoch(G, D, opt_g, opt_d)\n",
    "    p_real, p_fake = evaluate(G, D)\n",
    "\n",
    "    p_real_history.append(p_real)\n",
    "    p_fake_history.append(p_fake)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1:3d}/{total_epochs} | p_real: {p_real:.4f} | p_fake: {p_fake:.4f}\")\n",
    "        show_grid(G(sample_noise(16)).view(-1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 학습 결과 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_real / p_fake 수렴 과정\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(p_real_history, label=\"p_real (진짜를 진짜로 판별)\")\n",
    "plt.plot(p_fake_history, label=\"p_fake (가짜를 진짜로 판별)\")\n",
    "plt.axhline(y=0.5, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"이상적 수렴점 (0.5)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(\"GAN Training Progress\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"p_real과 p_fake가 모두 0.5에 수렴하면 이상적인 상태입니다.\")\n",
    "print(\"→ Discriminator가 진짜/가짜를 구별하지 못한다는 의미\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 생성 이미지\n",
    "print(\"최종 Generator가 생성한 패션 아이템 이미지 (4×4):\")\n",
    "show_grid(G(sample_noise(16)).view(-1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "### GAN 핵심 개념\n",
    "\n",
    "| 구성 요소 | 역할 | 목표 |\n",
    "|---|---|---|\n",
    "| Generator | 노이즈 → 가짜 이미지 | Discriminator를 속이기 |\n",
    "| Discriminator | 이미지 → 진짜 확률 | Generator를 간파하기 |\n",
    "| 적대적 학습 | 두 모델의 경쟁 | 균형점(Nash Equilibrium)에 도달 |\n",
    "\n",
    "### GAN 학습의 어려움\n",
    "- **모드 붕괴(Mode Collapse)**: Generator가 한 가지 이미지만 반복 생성\n",
    "- **학습 불안정**: Generator와 Discriminator 간 학습 속도 균형이 어려움\n",
    "- **평가 기준 부재**: 생성 이미지의 품질을 객관적으로 측정하기 어려움\n",
    "\n",
    "### 시리즈 전체 요약\n",
    "\n",
    "| 편 | 모델 | 핵심 |\n",
    "|---|---|---|\n",
    "| 1편 | Linear | 이미지 = 숫자, 학습 = weight 업데이트 |\n",
    "| 2편 | FC NN | 계층을 쌓으면 파라미터가 폭발 |\n",
    "| 3편 | CNN | 지역성 활용 → 적은 파라미터로 높은 성능 |\n",
    "| 4편 | GAN | Generator vs Discriminator 경쟁 → 이미지 생성 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
