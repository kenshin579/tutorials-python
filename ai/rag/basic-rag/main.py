"""
ê¸°ë³¸ RAG ì±—ë´‡ - ì¶œì²˜ í‘œì‹œ + ëŒ€í™”í˜• ë£¨í”„ë¥¼ ì§€ì›í•˜ëŠ” RAG ì˜ˆì œ

ì‚¬ìš©ë²•:
    1. ì˜ì¡´ì„± ì„¤ì¹˜: pip install -e .
    2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •: export OPENAI_API_KEY=your_api_key
    3. docs/ ë””ë ‰í† ë¦¬ì— ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ë°°ì¹˜
    4. ì¸ë±ì‹±: python main.py index
    5. ë‹¨ì¼ ì§ˆì˜: python main.py query "ì²­ì•½ì² íšŒ ê¸°ê°„ì€?"
    6. ëŒ€í™” ëª¨ë“œ: python main.py chat
"""

import os
import sys

from langchain_chroma import Chroma
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

CHROMA_DIR = "./chroma_db"
DOCS_DIR = "./docs"

embeddings = OpenAIEmbeddings(model="text-embedding-3-small")


# â”€â”€ 1ë‹¨ê³„: ë¬¸ì„œ ì¸ë±ì‹± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def index_documents():
    """ë¬¸ì„œë¥¼ ë¡œë“œ â†’ ì²­í‚¹ â†’ ì„ë² ë”© â†’ ë²¡í„° ì €ì¥ì†Œì— ì €ì¥"""

    # ë¬¸ì„œ ë¡œë“œ
    loader = DirectoryLoader(DOCS_DIR, glob="**/*.md", loader_cls=TextLoader)
    documents = loader.load()
    print(f"ë¡œë“œëœ ë¬¸ì„œ: {len(documents)}ê°œ")

    # ì²­í‚¹
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    chunks = splitter.split_documents(documents)
    print(f"ìƒì„±ëœ ì²­í¬: {len(chunks)}ê°œ")

    # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
    Chroma.from_documents(chunks, embeddings, persist_directory=CHROMA_DIR)
    print("ì¸ë±ì‹± ì™„ë£Œ!")


# â”€â”€ 2ë‹¨ê³„: ìœ ì‚¬ë„ ê²€ìƒ‰ + ì¶œì²˜ í‘œì‹œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def retrieve_with_sources(vector_store, question: str, k: int = 3):
    """ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ì¶œì²˜ ì •ë³´ë¥¼ ë°˜í™˜"""
    results = vector_store.similarity_search_with_relevance_scores(question, k=k)

    sources = []
    for doc, score in results:
        source_file = os.path.basename(doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ"))
        sources.append(
            {
                "file": source_file,
                "score": score,
                "preview": doc.page_content[:80] + "...",
            }
        )
    return results, sources


def format_docs(docs_with_scores):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    return "\n\n".join(doc.page_content for doc, _score in docs_with_scores)


def print_sources(sources):
    """ì¶œì²˜ ì •ë³´ë¥¼ í¬ë§·íŒ…í•˜ì—¬ ì¶œë ¥"""
    print("\nğŸ“š ì°¸ì¡° ë¬¸ì„œ:")
    for i, src in enumerate(sources, 1):
        print(f"  [{i}] {src['file']} (ìœ ì‚¬ë„: {src['score']:.3f})")
        print(f"      {src['preview']}")


# â”€â”€ 3ë‹¨ê³„: ì§ˆì˜ì‘ë‹µ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_chain(vector_store):
    """RAG ì²´ì¸ì„ êµ¬ì„±í•˜ì—¬ ë°˜í™˜"""

    prompt = ChatPromptTemplate.from_template(
        """ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
ì»¨í…ìŠ¤íŠ¸ì— ë‹µì´ ì—†ìœ¼ë©´ "í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}
ë‹µë³€:"""
    )

    retriever = vector_store.as_retriever(search_kwargs={"k": 3})

    chain = (
        {"context": retriever | format_docs_simple, "question": RunnablePassthrough()}
        | prompt
        | ChatOpenAI(model="gpt-4o", temperature=0)
        | StrOutputParser()
    )
    return chain


def format_docs_simple(docs):
    """retrieverìš© í¬ë§· í•¨ìˆ˜ (ì ìˆ˜ ì—†ì´ Document ë¦¬ìŠ¤íŠ¸)"""
    return "\n\n".join(doc.page_content for doc in docs)


def query(question: str):
    """ë‹¨ì¼ ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€ ìƒì„± + ì¶œì²˜ í‘œì‹œ"""

    vector_store = Chroma(persist_directory=CHROMA_DIR, embedding_function=embeddings)

    # ì¶œì²˜ ì •ë³´ê°€ í¬í•¨ëœ ê²€ìƒ‰
    results, sources = retrieve_with_sources(vector_store, question)

    # ì²´ì¸ìœ¼ë¡œ ë‹µë³€ ìƒì„±
    chain = build_chain(vector_store)
    answer = chain.invoke(question)

    print(f"\nğŸ’¬ ì§ˆë¬¸: {question}")
    print(f"\nğŸ¤– ë‹µë³€: {answer}")
    print_sources(sources)


# â”€â”€ 4ë‹¨ê³„: ëŒ€í™”í˜• ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def chat():
    """ëŒ€í™”í˜• ëª¨ë“œ - ë°˜ë³µì ìœ¼ë¡œ ì§ˆë¬¸í•˜ê³  ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆë‹¤"""

    vector_store = Chroma(persist_directory=CHROMA_DIR, embedding_function=embeddings)
    chain = build_chain(vector_store)

    print("=" * 50)
    print("RAG ì±—ë´‡ ëŒ€í™” ëª¨ë“œ")
    print("ì¢…ë£Œ: quit ë˜ëŠ” exit ì…ë ¥")
    print("=" * 50)

    while True:
        try:
            question = input("\nâ“ ì§ˆë¬¸: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if not question:
            continue
        if question.lower() in ("quit", "exit", "q"):
            print("ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # ì¶œì²˜ í¬í•¨ ê²€ìƒ‰
        results, sources = retrieve_with_sources(vector_store, question)

        # ë‹µë³€ ìƒì„±
        answer = chain.invoke(question)

        print(f"\nğŸ¤– ë‹µë³€: {answer}")
        print_sources(sources)


# â”€â”€ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python main.py [index|query|chat]")
        print("  index         - docs/ ë””ë ‰í† ë¦¬ì˜ ë¬¸ì„œë¥¼ ì¸ë±ì‹±")
        print("  query <ì§ˆë¬¸>  - ë‹¨ì¼ ì§ˆë¬¸ì— ë‹µë³€")
        print("  chat          - ëŒ€í™”í˜• ëª¨ë“œ ì‹œì‘")
        sys.exit(1)

    command = sys.argv[1]
    if command == "index":
        index_documents()
    elif command == "query":
        question = sys.argv[2] if len(sys.argv) > 2 else "ì²­ì•½ì² íšŒ ê¸°ê°„ì€?"
        query(question)
    elif command == "chat":
        chat()
    else:
        print(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹: {command}")
