#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import argparse
import os
import shutil
import sys

import cv2
import nltk
import numpy as np
import rawpy
from PIL import Image


# todo: xmp ìƒì„±ì´ ì•ˆë˜ëŠ” ì´ìŠˆê°€ ìˆìŒ
# todo: ì‚¬ëŒ ì–¼êµ´ íë¦¼ íŒë‹¨ì´ ì˜ ì•ˆë¨ - ì‹¤ì œë¡œ ì‹¤í–‰í•´ë³´ê¸°...

# ì–¼êµ´ ê°ì§€ ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸°
try:
    from face_detection import detect_faces, analyze_face_sharpness
    FACE_DETECTION_AVAILABLE = True
    print("ì–¼êµ´ ê°ì§€ ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
except ImportError:
    print("ì–¼êµ´ ê°ì§€ ëª¨ë“ˆì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì–¼êµ´ ê°ì§€ ê¸°ëŠ¥ ë¹„í™œì„±í™”.")
    FACE_DETECTION_AVAILABLE = False

# XMP ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì‹œë„ - ì‹¤íŒ¨í•´ë„ í”„ë¡œê·¸ë¨ì€ ê³„ì† ì‹¤í–‰
XMP_AVAILABLE = False

# OpenCVì˜ ì–¼êµ´ ê°ì§€ê¸°ë¥¼ ìœ„í•œ ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
FACE_CASCADE_PATH = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'

try:
    import libxmp
    from libxmp import XMPFiles, consts
    XMP_AVAILABLE = True
    print("XMP ë©”íƒ€ë°ì´í„° íƒœê·¸ ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"XMP ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
    print("XMP íƒœê·¸ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤. íƒœê·¸ëŠ” ìƒì„±ë˜ì§€ë§Œ XMP íŒŒì¼ì€ ë§Œë“¤ì–´ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    print("XMP íƒœê·¸ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ Exempi ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:")
    print("  brew install exempi")
    print("  pip install python-xmp-toolkit")

# NLTK ë¶ˆìš©ì–´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œë„
try:
    print("NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...")
    nltk.download('stopwords', quiet=False)
except Exception as e:
    print(f"NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

try:
    from transformers import BlipProcessor, BlipForConditionalGeneration
except ImportError:
    print("transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íƒœê·¸ ìƒì„± ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    BlipProcessor = None
    BlipForConditionalGeneration = None

try:
    from nltk.corpus import stopwords
    # ì˜ì–´ ë¶ˆìš©ì–´ ëª©ë¡ ë¡œë“œ ì‹œë„
    try:
        STOPWORDS = set(stopwords.words('english'))
        # ì¶”ê°€ë¡œ ì œê±°í•  ìˆ˜ ìˆëŠ” ì¼ë°˜ì ì¸ ë‹¨ì–´ë“¤
        ADDITIONAL_STOPWORDS = {'of', 'with', 'in', 'on', 'at', 'from', 'to', 'for'}
        STOPWORDS.update(ADDITIONAL_STOPWORDS)
    except LookupError:
        print("ê²½ê³ : NLTK stopwords ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        # ê¸°ë³¸ ë¶ˆìš©ì–´ ëª©ë¡ ì œê³µ
        STOPWORDS = {'a', 'an', 'the', 'and', 'or', 'but', 'if', 'because', 'as', 'what',
                    'which', 'this', 'that', 'these', 'those', 'then', 'just', 'so', 'than',
                    'such', 'when', 'who', 'how', 'where', 'why', 'of', 'with', 'in', 'on',
                    'at', 'from', 'to', 'for'}
except ImportError:
    print("NLTK ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¶ˆìš©ì–´ ëª©ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    STOPWORDS = {'a', 'an', 'the', 'and', 'or', 'but', 'if', 'because', 'as', 'what',
                'which', 'this', 'that', 'these', 'those', 'then', 'just', 'so', 'than',
                'such', 'when', 'who', 'how', 'where', 'why', 'of', 'with', 'in', 'on',
                'at', 'from', 'to', 'for'}


def detect_main_object(image):
    """
    ì´ë¯¸ì§€ì—ì„œ ì£¼ìš” ê°ì²´ ì˜ì—­ì„ ê°ì§€í•©ë‹ˆë‹¤.
    ê°„ë‹¨í•œ ë°©ë²•ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ê²©ìë¡œ ë‚˜ëˆ„ê³ , ê° ì˜ì—­ì˜ Laplacian ë¶„ì‚° ê°’ì´ ê°€ì¥ ë†’ì€ ì˜ì—­ì„
    ì£¼ìš” ê°ì²´ ì˜ì—­ìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.

    Args:
        image: ë¶„ì„í•  ì´ë¯¸ì§€

    Returns:
        tuple: ì£¼ìš” ê°ì²´ ì˜ì—­ì˜ ë§ˆìŠ¤í¬, ì„ ëª…ë„ ì ìˆ˜
    """
    height, width = image.shape[:2]
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) > 2 else image

    # ì´ë¯¸ì§€ë¥¼ 5x5 ê·¸ë¦¬ë“œë¡œ ë‚˜ëˆ•ë‹ˆë‹¤
    grid_h, grid_w = 5, 5
    cell_h, cell_w = height // grid_h, width // grid_w

    # ê° ì…€ì˜ Laplacian ë¶„ì‚° ê³„ì‚°
    cell_scores = np.zeros((grid_h, grid_w))
    for i in range(grid_h):
        for j in range(grid_w):
            y1, y2 = i * cell_h, (i + 1) * cell_h
            x1, x2 = j * cell_w, (j + 1) * cell_w

            # ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
            y2 = min(y2, height)
            x2 = min(x2, width)

            cell = gray[y1:y2, x1:x2]
            lap_var = cv2.Laplacian(cell, cv2.CV_64F).var()
            cell_scores[i, j] = lap_var

    # ì¤‘ì‹¬ë¶€ ì˜ì—­ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬ (ì¤‘ì‹¬ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì£¼ìš” ê°ì²´ì¼ ê°€ëŠ¥ì„± ë†’ìŒ)
    center_weight = np.zeros((grid_h, grid_w))
    center_y, center_x = grid_h // 2, grid_w // 2
    for i in range(grid_h):
        for j in range(grid_w):
            # ì¤‘ì‹¬ìœ¼ë¡œë¶€í„°ì˜ ê±°ë¦¬ ê³„ì‚°
            dist = np.sqrt((i - center_y)**2 + (j - center_x)**2)
            # ê±°ë¦¬ì— ë°˜ë¹„ë¡€í•˜ëŠ” ê°€ì¤‘ì¹˜ (ê±°ë¦¬ê°€ ë©€ìˆ˜ë¡ ê°€ì¤‘ì¹˜ ê°ì†Œ)
            center_weight[i, j] = 1 / (1 + dist)

    # ë¶„ì‚° ì ìˆ˜ì™€ ì¤‘ì‹¬ ê°€ì¤‘ì¹˜ë¥¼ ê²°í•©
    weighted_scores = cell_scores * center_weight

    # ìƒìœ„ 25% ì ìˆ˜ë¥¼ ê°€ì§„ ì…€ì„ ì£¼ìš” ê°ì²´ ì˜ì—­ìœ¼ë¡œ ê°„ì£¼
    threshold = np.percentile(weighted_scores, 75)
    main_object_cells = weighted_scores >= threshold

    # ì£¼ìš” ê°ì²´ ë§ˆìŠ¤í¬ ìƒì„±
    mask = np.zeros((height, width), dtype=np.uint8)
    for i in range(grid_h):
        for j in range(grid_w):
            if main_object_cells[i, j]:
                y1, y2 = i * cell_h, (i + 1) * cell_h
                x1, x2 = j * cell_w, (j + 1) * cell_w

                # ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
                y2 = min(y2, height)
                x2 = min(x2, width)

                mask[y1:y2, x1:x2] = 255

    # ì£¼ìš” ê°ì²´ ì˜ì—­ì˜ Laplacian ë¶„ì‚° í‰ê·  ê³„ì‚°
    main_object_score = np.mean(weighted_scores[main_object_cells])

    return mask, main_object_score


def is_main_object_blurry(image, blur_threshold=70.0):
    """
    ì£¼ìš” ê°ì²´ì˜ íë¦¼ ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.
    ì‚¬ëŒì´ ì£¼ìš” ê°ì²´ì¸ ê²½ìš°ì—ëŠ” ì–¼êµ´ì´ í”ë“¤ë ¸ëŠ”ì§€ë¥¼ ìš°ì„ ì ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.

    Args:
        image: ë¶„ì„í•  ì´ë¯¸ì§€
        blur_threshold: íë¦¼ íŒë‹¨ ì„ê³„ê°’

    Returns:
        tuple: (is_blurry, main_object_score) - íë¦¼ ì—¬ë¶€ì™€ ì„ ëª…ë„ ì ìˆ˜
    """
    # ì–¼êµ´ ê°ì§€ ê¸°ëŠ¥ì´ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
    if FACE_DETECTION_AVAILABLE:
        # ì–¼êµ´ ê°ì§€
        faces = detect_faces(image)

        # ì–¼êµ´ì´ ê°ì§€ëœ ê²½ìš°
        if len(faces) > 0:
            print(f"ì‚¬ëŒ ì–¼êµ´ì´ {len(faces)}ê°œ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")

            # ì–¼êµ´ ì˜ì—­ì˜ ì„ ëª…ë„ ë¶„ì„
            # ì–¼êµ´ ì˜ì—­ì€ ì¤‘ìš”í•˜ë¯€ë¡œ, ì¼ë°˜ ê¸°ì¤€ë³´ë‹¤ ë” ì—„ê²©í•œ ì„ê³„ê°’(1.3ë°°) ì ìš©
            face_blur_threshold = blur_threshold * 1.3
            # í•¨ìˆ˜ê°€ 3ê°œì˜ ê°’ì„ ë°˜í™˜í•˜ë¯€ë¡œ ì–¸íŒ¨í‚¹ ë°©ì‹ ìˆ˜ì •
            is_face_blurry, face_score, _ = analyze_face_sharpness(image, faces, face_blur_threshold)

            print(f"ì–¼êµ´ ì„ ëª…ë„: {face_score:.2f}, ì–¼êµ´ íë¦¼ ì„ê³„ê°’: {face_blur_threshold:.2f}")

            # ì–¼êµ´ì´ íë¦¿í•˜ë©´ ì „ì²´ ì´ë¯¸ì§€ê°€ íë¦¿í•œ ê²ƒìœ¼ë¡œ íŒë‹¨
            if is_face_blurry:
                print("ì–¼êµ´ì´ íë¦¿í•˜ì—¬ í”ë“¤ë¦° ì‚¬ì§„ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.")
                return True, face_score
            else:
                print("ì–¼êµ´ì´ ì„ ëª…í•˜ì—¬ ì •ìƒ ì‚¬ì§„ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.")
                return False, face_score

    # ì–¼êµ´ ê°ì§€ ë¶ˆê°€ëŠ¥í•˜ê±°ë‚˜ ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì€ ê²½ìš°: ì¼ë°˜ì ì¸ íë¦¼ íŒë‹¨
    mask, main_object_score = detect_main_object(image)
    print(f"ì£¼ìš” ê°ì²´ ì„ ëª…ë„: {main_object_score:.2f}, ì¼ë°˜ íë¦¼ ì„ê³„ê°’: {blur_threshold:.2f}")

    # ì£¼ìš” ê°ì²´ ì˜ì—­ì´ ì„ê³„ê°’ë³´ë‹¤ ë‚®ìœ¼ë©´ íë¦¼ìœ¼ë¡œ íŒë‹¨
    is_blurry = main_object_score < blur_threshold

    return is_blurry, main_object_score


def save_xmp_tags(image_path, tags):
    """
    ì´ë¯¸ì§€ íŒŒì¼ì— ëŒ€í•œ XMP ì‚¬ì´ë“œì¹´ íŒŒì¼ì„ ìƒì„±í•˜ê³  íƒœê·¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        image_path: ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        tags: ì €ì¥í•  íƒœê·¸ ëª©ë¡
    """
    if not XMP_AVAILABLE:
        print(f"XMP ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ íƒœê·¸ë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return False

    try:
        # XMP íŒŒì¼ ê²½ë¡œ ìƒì„± (ì›ë³¸ íŒŒì¼ëª….xmp)
        xmp_path = f"{image_path}.xmp"

        # XMP íŒŒì¼ ìƒì„±
        xmpfile = XMPFiles(file_path=image_path, open_forupdate=True)

        # ê¸°ì¡´ XMP ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒˆë¡œ ìƒì„±
        xmp = xmpfile.get_xmp() if xmpfile.get_xmp() else libxmp.XMPMeta()

        # íƒœê·¸ë¥¼ DC(Dublin Core) ì£¼ì œë¡œ ì €ì¥
        for i, tag in enumerate(tags):
            xmp.append_array_item(libxmp.consts.XMP_NS_DC, 'subject', tag, {})

        # Microsoft Photo íƒœê·¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ë„ ì €ì¥
        for i, tag in enumerate(tags):
            xmp.append_array_item(libxmp.consts.XMP_NS_Microsoft, 'LastKeywordXMP', tag, {})

        # Adobe Lightroom í‚¤ì›Œë“œì—ë„ ì €ì¥
        if tags:
            # í‚¤ì›Œë“œ ë°°ì—´ë¡œ í•¨ê»˜ ì €ì¥
            keywords_str = ", ".join(tags)
            xmp.set_property(libxmp.consts.XMP_NS_Lightroom, 'hierarchicalSubject', keywords_str)

        # ë³€ê²½ì‚¬í•­ ì €ì¥
        if xmpfile.can_put_xmp(xmp):
            xmpfile.put_xmp(xmp)
            xmpfile.close_file()

            # ì‚¬ì´ë“œì¹´ íŒŒì¼ë¡œ ì €ì¥
            xmp.serialize_and_save(xmp_path)
            print(f"XMP íƒœê·¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {xmp_path}")
            return True
        else:
            print(f"XMP íƒœê·¸ë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            return False

    except Exception as e:
        print(f"XMP íƒœê·¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False


def process_arw(image_path, blur_threshold=100.0, model=None, processor=None):
    """
    ARW íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ íë¦¼ ì •ë„ë¥¼ ì¸¡ì •í•˜ê³  íƒœê·¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        image_path (str): ARW íŒŒì¼ ê²½ë¡œ
        blur_threshold (float): íë¦¼ íŒë‹¨ ê¸°ì¤€ê°’
        model: ì´ë¯¸ì§€ íƒœê¹…ì— ì‚¬ìš©í•  ëª¨ë¸
        processor: ì´ë¯¸ì§€ ì „ì²˜ë¦¬ê¸°

    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼ (is_blurry, tags, lap_var)
    """
    # 1. ARW â†’ RGB
    try:
        with rawpy.imread(image_path) as raw:
            rgb = raw.postprocess()
    except Exception as e:
        print(f"Error processing {image_path}: {str(e)}")
        return None

    # 2. í–¥ìƒëœ íë¦¼ íŒë‹¨ - ì£¼ìš” ê°ì²´ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„
    is_blurry, main_object_score = is_main_object_blurry(rgb, blur_threshold)

    # ì „ì²´ ì´ë¯¸ì§€ì— ëŒ€í•œ Laplacian ë¶„ì‚°ë„ ê³„ì‚° (ì°¸ê³ ìš©)
    gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)
    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()

    # 3. í”ë“¤ë¦¬ì§€ ì•Šì€ ì‚¬ì§„ì— ëŒ€í•´ì„œë§Œ íƒœê·¸ ìƒì„±
    tags = []
    if not is_blurry and model is not None and processor is not None:
        try:
            image_pil = Image.fromarray(rgb)
            inputs = processor(image_pil, return_tensors="pt")
            out = model.generate(**inputs)
            caption = processor.decode(out[0], skip_special_tokens=True)

            # ë¶ˆìš©ì–´ë¥¼ ì œì™¸í•œ íƒœê·¸ ìƒì„±
            words = caption.lower().split()
            filtered_words = [word for word in words if word not in STOPWORDS and len(word) > 1]
            tags = filtered_words[:5]  # ìµœëŒ€ 5ê°œ íƒœê·¸ ì¶”ì¶œ

            if not tags:  # í•„í„°ë§ í›„ íƒœê·¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë‹¨ì–´ ì‚¬ìš©
                tags = words[:5]

            print(f"Caption: '{caption}', Tags: {tags}")

            # 4. íƒœê·¸ë¥¼ XMP íŒŒì¼ë¡œ ì €ì¥
            if tags:
                save_xmp_tags(image_path, tags)

        except Exception as e:
            print(f"Error generating tags for {image_path}: {str(e)}")
    else:
        if is_blurry:
            print(f"{image_path}ëŠ” í”ë“¤ë¦° ì´ë¯¸ì§€ë¡œ íƒœê·¸ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        elif model is None:
            print(f"íƒœê¹… ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ íƒœê·¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    return {
        "is_blurry": is_blurry,
        "tags": tags,
        "lap_var": laplacian_var,
        "main_object_score": main_object_score
    }


def load_model():
    """
    ì´ë¯¸ì§€ íƒœê¹…ì„ ìœ„í•œ ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    try:
        processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
        model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
        return model, processor
    except Exception as e:
        print(f"Warning: Failed to load image tagging model: {str(e)}")
        print("Will proceed without tagging functionality.")
        return None, None


def main():
    parser = argparse.ArgumentParser(description="ARW íŒŒì¼ ì²˜ë¦¬ ë° íƒœê¹… í”„ë¡œê·¸ë¨")
    parser.add_argument("--src", default="./raw_photos", help="ì²˜ë¦¬í•  RAW íŒŒì¼ì´ ìˆëŠ” ì†ŒìŠ¤ í´ë” ê²½ë¡œ (ê¸°ë³¸ê°’: ./raw_photos)")
    parser.add_argument("--threshold", type=float, default=70.0, help="íë¦¼ íŒë‹¨ ê¸°ì¤€ê°’ (ê¸°ë³¸ê°’: 70.0)")
    args = parser.parse_args()

    # ì†ŒìŠ¤ í´ë” í™•ì¸
    if not os.path.exists(args.src):
        print(f"Error: Source folder '{args.src}' does not exist.")
        return 1

    # src í´ë” ì•„ë˜ì— deleted í´ë” ê²½ë¡œ ìƒì„±
    deleted_folder = os.path.join(args.src, "deleted")

    # ì‚­ì œëœ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  í´ë” ìƒì„±
    os.makedirs(deleted_folder, exist_ok=True)
    print(f"í”ë“¤ë¦° ì‚¬ì§„ì€ {deleted_folder} í´ë”ë¡œ ì´ë™ë©ë‹ˆë‹¤.")

    # ëª¨ë¸ ë¡œë“œ
    model, processor = load_model()

    # ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜ ê³„ì‚°
    arw_files = [f for f in os.listdir(args.src) if f.lower().endswith('.arw')]
    total_files = len(arw_files)

    if total_files == 0:
        print(f"No ARW files found in {args.src}")
        return 0

    print(f"Processing {total_files} ARW files...")

    # íŒŒì¼ ì²˜ë¦¬
    processed = 0
    blurry = 0

    for filename in arw_files:
        full_path = os.path.join(args.src, filename)
        result = process_arw(full_path, args.threshold, model, processor)

        if result is None:
            continue

        processed += 1

        if result["is_blurry"]:
            blurry += 1
            shutil.move(full_path, os.path.join(deleted_folder, filename))
            print(f"ğŸŒ«ï¸  {filename}: Blurry image moved (Sharpness: {result['lap_var']:.2f})")
        else:
            tags_str = ", ".join(result['tags'])
            print(f"âœ… {filename}: {tags_str} (Sharpness: {result['lap_var']:.2f})")

    # ìš”ì•½ ì¶œë ¥
    print(f"\nProcessed {processed} files. Moved {blurry} blurry images to {deleted_folder}")
    return 0


if __name__ == "__main__":
    sys.exit(main())
